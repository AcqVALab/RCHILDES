---
title: "Working with the Child Language Data Exchange System (CHILDES) using R"
author: "Martin Schweinberger"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output:
  html_document:
    theme: cosmo
    highlight: tango
bibliography: bibliography.bib
link-citations: yes
---

```{r acqva1, echo=F, fig.cap="", message=FALSE, warning=FALSE, out.width='100%'}
knitr::include_graphics("https://slcladal.github.io/images/acqva.jpg")
```

# Introduction{-}

This workshop shows how you can use and analyze the *Child Language Data Exchange System* (CHILDES) data base using R. All the files that are needed for this tutorial can be downloaded [here](https://github.com/AcqVALab/RCHILDES). 

## Aims{-}

The aim of this workshop will be to introduce you to the Child Language Data Exchange System (CHILDES) data base and to show you how you can use it in your own studies.

The workshop consists of 2 parts:

1. **Introduction** on September 15:  this part shows how you can access and work with CHILDES data using R.

2. **Practical issues** on September 22: this part is a practical Q&A about your own studies and things that you want me to explain so that you can do your own research.

## Prerequisites{-}

In order to follow the content of this workshop, you should already be familiar with R/Rstudio. If you are not familiar with R/RStudio, please go through [this introduction to R/RStudio](https://slcladal.github.io/intror.html). In addition, it is recommended to be familiar with regular expressions ([this tutorials](https://slcladal.github.io/regex.html) contains an overview of regular expressions that are used in this tutorial). 

You should also have downloaded  and installed R and RStudio. [This tutorial](https://slcladal.github.io/intror.html) contains links to detailed how-tos on how to download and install R and RStudio.

## Aims of the workshop{-}

After this workshop, you should be able to 

* load files from the CHILDES data base into R/RStudio

* process and extract metadata from CHILDES files in R/RStudio

* search for words and phrases in CHILDES data using R/RStudio

* visualize and tabulate results in R/RStudio.  

## Why R?{-}

You can analyze CHILDES data with a variety of tools, for instance with AntConc or CLAN. 


If you simply want to extract examples from CHILDES data, then I highly recommend you use AntConc - it is a very user-friendly, quick and intuitive concordancing program. However, if you want to perform analyses, then you need to combine AntConc with other software tools which renders such analyses more complex and cumbersome. As using different software tools to analyze CHILDES data is also complex, it makes sense to use R instead.

If you only ever want to analyze CHILDES data, then I strongly recommend you use CLAN (Computerized Language Analysis) as this tool was specifically designed to analyze CHILDES data. However, it is not a useful tool for other analyses of language data.

R is free, open-source, and a fully fledged and thus extremely powerful and flexible programming language. Once you have mastered R, you will be able to perform very complex and sophisticated tasks. As such, learning R is a very handy skill to have. In addition, the ability to write share-able scrips enables you to make your work flow 100% transparent and reproducible. Furthermore, once you have a script to perform certain task, you can re-use, copy, and edit it over and over again. 

## How to get started{-}

1.

a. Download the RCHILDES folder from CANVAS

b. Unzip that folder and sore it somewhere on your computer.


2. Please download and install R and RStudio ([here](https://slcladal.github.io/intror.html#Installing_R_and_RStudio) is a more detailed description on how to download R and RStudio with links to additional document that will help you in case you encounter issues)

* R (just Google *download R* click on the top most website and follow the instructions)

* the Open Source License Free Desktop version of RStudio ([here is a link](https://www.rstudio.com/products/rstudio/download/) where you can download this version of RStudio).

## Working in RStudio{-}

Once you have installed R and RStudio, open RStudio, click on `New Project`, then click on *Existing directory*, and then navigate to the *RCHILDESp* folder that you have just created and click *Enter*.

Then, download the file `childes.Rmd` from `https://github.com/AcqVALab/RCHILDES` and store it in your workshop folder. Once you have stored the file in your workshop folder, you should see it in the lower right pane in RStudio. Double click that file. This should lead to the file opening in the upper left pane in RStudio.

All you have to do from here is to click on the *Knit* command which is located at the top-left edge of the upper left pane in RStudio. When you click on *Knit*, the rendered tutorial should appear in a new window.

To run code chunks, simply simply click on the green play button which is located at the top-right edge of code chunk. When you click on that play button, the code in the chunk will be executed and the result of the code chunk  may appear if the code has a visible output.

# The HSLLD{-}

This section provides some info on the data that we will analyze in this workshop. In this workshop, we will use data from the *Home-School Study of Language and Literacy Development* (HSLLD) corpus which part of the CHILDES data base. The HSLLD is described in more detail below so that you have a more detailed understanding of the data we are dealing with in this workshop.

## About the HSLLD

The *Home-School Study of Language and Literacy Development* (HSLLD) began in 1987 under the leadership of  Patton Tabors and with Catherine E. Snow and David K. Dickinson as  primary investigators. The original purpose of the HSLLD was to investigate the social prerequisites to literacy success. 


The initial number of participants was 83 American English speaking, racially diverse, preschool age children from low-income families growing up in or around Boston, Massachusetts. Seventy-four of these children were still participating at age 5. The sample consists of 38 girls and 36 boys. Forty-seven children were Caucasian, 16 were African American, six were of Hispanic origin, and five were biracial. 

Children were visited once a year in their home from age 3 â€“ 5 and then again when they were in 2nd and 4th grade. Each visit lasted between one and three hours. Home visits consisted of a number of different tasks depending on the year. An outline of the different tasks for each visit is presented below. 

Activities during **Home Visit 1** (HV1): Book reading (BR), Elicited report (ER), Mealtime (MT), Toy Play (TP)  

Activities during **Home Visit 2** (HV2): Book reading (BR), Elicited report (ER), Mealtime (MT), Toy Play (TP)  

Activities during **Home Visit 3** (HV3): Book reading (BR), Elicited report (ER), Experimental task (ET), Mealtime (MT), Reading (RE), Toy play (TP)  

Activities during **Home Visit 5** (HV5): Book reading (BR), Letter writing (LW), Mealtime (MT)  

Activities during **Home Visit 7** (HV7): Experimental task (ET), Letter writing (LW), Mother definitions (MD), Mealtime (MT)  

```{r childes01, echo=FALSE, out.width= "40%", out.extra='style="float:right; padding:10px"'}
knitr::include_graphics("https://slcladal.github.io/images/childes01.png")
```

## Downloading the HSLLD{-}

* Go to the [CHILDES website](https://childes.talkbank.org/).



* In the section called *Database* click on *Index to Corpora*. 

```{r childes02, echo=F, eval = F, fig.cap="", message=FALSE, warning=FALSE, out.width='40%'}
knitr::include_graphics("https://slcladal.github.io/images/childes02.png")
```

* Then, click on *Eng-NA* and then scroll down and click on *HSLLD*

```{r childes03, echo=F, eval = F, fig.cap="", message=FALSE, warning=FALSE, out.width='40%'}
knitr::include_graphics("https://slcladal.github.io/images/childes03.png")
```

* Click on *Download transcripts* and then download and store the zip-folder called *HSLLD.zip* somewhere on your computer.

* Next, unzip the HSLLD.zip file and store the resulting unzipped HSLLD in the*data* subfolder in your workshop folder.


# Preparation{-}

Before we do anything else, we prepare our session. In a first step, we will update the latest version of R on our computer. To do this, we install and load the `installr` package and then update to the latest version of R usign the `updateR` package fro the `installr` package.


```{r prep0, eval = F, message=F, warning=F}
# installing and loading the latest installr package:
install.packages("installr")  # install installr
library(installr)             # load installr
installr::updateR()           # updating R
```

Next, we prepare the session which means that we set options, install packages that we will need, and define paths. Options are there to tell R how to *do things*. For example, the command `options(stringsAsFactors = F) ` prevents R from converting strings (text) into factors (don't worry about what factors are at this point). Packages need to be installed because R comes in a basic version and if we want to do something more fancy, then we need to install add-ons (packages). Packages only to to be installed once - so you do not need to install them again when you have installed a package once. Defining paths is useful because it shows readers at the beginning of documents where they may have to adapt scripts when they want to run them on their own computer (where the paths may be different).

```{r prep1, eval = F, message=F, warning=F}
# set options
options(stringsAsFactors = F)          # no automatic data transformation
options("scipen" = 100, "digits" = 12) # suppress math annotation
options(max.print=1000)                # show maximally 1000 elements in the output
# install packages
install.packages("tidyverse")
install.packages("flextable")
install.packages("knitr")
install.packages("here"))
# load packages
library(tidyverse)
library(flextable)
library(knitr)
library(here)
# specify path to corpus
corpuspath <- here::here("data", "HSLLD")
```

```{r prep2, eval = T, echo = F, message=F, warning=F}
# set options
options(stringsAsFactors = F)          # no automatic data transformation
options("scipen" = 100, "digits" = 12) # suppress math annotation
options(max.print=1000)                # show maximally 1000 elements in the output
# load packages
library(tidyverse)
library(flextable)
library(knitr)
library(here)
# specify path to corpus
corpuspath <- here::here("data", "HSLLD")
```


If you encounter problems with loading packages, execute the following code chunk manually but make sure that you replace the package name - in the code below `vctrs` with the name of the package that is mentioned in the error message.

```{r prep4, eval = F, echo = T, message=F, warning=F}
install.packages("vctrs")
```


Before we continue, it is important to think about what we want to do!

In this workshop, we want to load the CHILDES data and convert the data into a format that we can then use to extract information from it. Optimally, the data should have the following format once we have processed the data:

```{r childes_01_01, echo = F, eval = T}
id <- data.frame(1:6)
id <- id %>%
  dplyr::rename("id" = colnames(id)[1]) %>%
  dplyr::mutate(file = c("aab", "aab", "aab", "aab", "aab", "aab"),
                childage = c("4;6", "4;6", "4;6", "4;6", "4;6", "4;6"),
                child = c("ben", "ben", "ben", "ben", "ben", "ben"),
                speaker = c("MOT", "MOT", "ben", "MOT", "ben", "MOT"),
                utterance = c("How are you ?", "Ben ?", "Okay", "Are you hungry ?", "No", "Sure ?"),
                tagged = c("How|WH are|BE you|PN ?|PC", "Ben|NNP ?|PC", "Okay|RB", "Are|BE you|PN hungry|JJ ?|PC", "No|NG", "Sure|RB ?|PC"),
                comment = c("", "", "", "", "shakes head", ""))
```



```{r childes_01_02, echo = F, message=F, warning=F}
id <- data.frame(1:6)
id <- id %>%
  dplyr::rename("id" = colnames(id)[1]) %>%
  dplyr::mutate(file = c("aab", "aab", "aab", "aab", "aab", "aab"),
                childage = c("4;6", "4;6", "4;6", "4;6", "4;6", "4;6"),
                child = c("ben", "ben", "ben", "ben", "ben", "ben"),
                speaker = c("MOT", "MOT", "ben", "MOT", "ben", "MOT"),
                utterance = c("How are you ?", "Ben ?", "Okay", "Are you hungry ?", "No", "Sure ?"),
                tagged = c("How|WH are|BE you|PN ?|PC", "Ben|NNP ?|PC", "Okay|RB", "Are|BE you|PN hungry|JJ ?|PC", "No|NG", "Sure|RB ?|PC"),
                comment = c("", "", "", "", "shakes head", ""))
# inspect data
flextable::flextable(id) %>%
  flextable::autofit()
```

So we want to have the data in a tabular format and in this table, each utterance is in a separate line and each line should also contain information about the speaker and the file.

# Data processing

We start the analysis by preparing the R session. This mean that we set options and that we install as well as load packages that we will need. In addition, we specify the path to the unzipped CHILDES data that we will use. 

In a first step, we create a list called `cha` with the paths to the individual files in the HSLLD corpus. This tells the computer where to find the files it is supposed to load. The `list.files` function lists all files in the specified folder (the folder that is defined by the `corpuspath`) that end in `.cha`. To check if this has worked, we inspect the first 6 paths using the `head` function.

```{r childes_01_03, message=F, warning=F}
# list corpus files
cha = list.files(path = corpuspath, 
                 pattern = ".cha$", 
                 all.files = T,
                 full.names = T, 
                 recursive = T, 
                 ignore.case = T)
# use only first 6 files for testing
#cha <- cha[1:6]
# check the first 6 file paths
head(cha)
```

We now load the data and split it up into files. The `sapply` function loops each element in the `cha` object and performs specified actions on the (here, loading the content via the `scan` function, getting rid of white spaces and splitting the files when it finds the following sequences `*ABC1:` or `%ABC:`).

```{r childes_01_04, message=F, warning=F}
# create version of corpus fit for concordancing
corpus <- sapply(cha, function(x) {
  # load data
  x <- scan(x, what = "char", sep = "\t", quiet = T, quote = "", skipNul = T)
  # clean data
  x <- stringr::str_trim(x, side = "both") # remove superfluous white spaces at the edges of strings
  x <- stringr::str_squish(x)              # remove superfluous white spaces within strings
  x <- paste0(x, collapse = " ")           # paste all utterances ina file together
  # split files into indivisual utterances
  x <- strsplit(gsub("([%|*][a-z|A-Z]{2,4}[0-9]{0,1}:)", "~~~\\1", x), "~~~")
})
# inspect results
str(corpus[1:3])
```

We have now loaded the files into R, but the format is not yet structured in a wqy thatwe can use it - remember: we want the data to be in a tabular format.

## Extract file information{-}

Now, we extract information about the recording, e.g., the participants, the age of the child, the date of the recording etc. For this, we extract the first element of each file (because this first element contains all the relevant information bout the recording). To do this, we again use the `sapply` function (which is our looping function) and then tell R that it shall only retain the first element of each element (`x <- x[1]`).

```{r childes_01_05, message=F, warning=F}
# extract file info for each file
fileinfo <- sapply(corpus, function(x){ 
  # extract first element of each corpus file because this contains the file info
  x <- x[1]
  })
#inspect
fileinfo[1:3]
```

Now, we have one element for each file that contains all the relevant information about the file, like when the recording took place, how old the target child was, how was present during the recording etc.

## Extract file content{-}

Now, we extract the raw content from which we will extract the speaker, the utterance, the pos-tagged utterance, and any comments.Here, we loop over the `corpus` object with the `sapply` function and we remove the first element in each list (and we retain the second to last element of each element (`x <- x[2:length(x)]`)), then we paste everything else together using the `paste0` function and then, we split the whole conversation into utterances that start with a speaker id (e.g. `*MOT:`). The latter is done by the sequence `stringr::str_split(stringr::str_replace_all(x, "(\\*[A-Z])", "~~~\\1"), "~~~")`.

  
```{r childes_01_06, message=F, warning=F}
content <- sapply(corpus, function(x){
  x <- x[2:length(x)]
  x <- paste0(x, collapse = " ")
  x <- stringr::str_split(stringr::str_replace_all(x, "(\\*[A-Z])", "~~~\\1"), "~~~")
})
# inspect data
content[[1]][1:6]
```

The data now consists of utterances but also the pos-tagged utterances and any comments. However, we use this form of the data to extract the clean utterances, the pos-tagged utterances and the comments and store them in different columns. 


## Extract information{-}

Now, we extract how many elements (or utterances) there are in each file by looping over the `content` object and extracting the number of elements within each element of the `content` object by using the `lenght` function. 

```{r childes_01_07, message=F, warning=F}
elements <- sapply(content, function(x){
  x <- length(x)
})
# inspect
head(elements)
```

## Generate table{-}

We now have the file names, the metadata for each file, and the content of each file (that is split into utterances). We use this information to generate a first table which holds the file name in one column, the file information in one column, and the raw file content in another column. To combine these three pieces of information though, we need to repeat the file names and the file information as often as there are utterances in each file. We perform this repetition using the `rep` function. Once we have as many file names and file information as there are utterances in each file, we can combine these three vectors into a table using the `data.frame` function. 


```{r childes_01_08, message=F, warning=F}
files <- rep(names(elements), elements)
fileinfo <- rep(fileinfo, elements)
rawcontent <- as.vector(unlist(content))
chitb <- data.frame(1:length(rawcontent),
                    files,
                    fileinfo,
                    rawcontent)
```

The table in its current form is shown below. We can see that the table has three columns: the first column holds the path to each file, the second contains the file information, and the third the utterances.

```{r childes_01_09, echo = F, message=F, warning=F}
# inspect data
flextable::flextable(head(chitb, 3)) %>%
  flextable::autofit()
```



# Process table{-}

We can now use the information in the two last columns to extract specific pieces of information from the data (which we will store in additional columns that we add to the table). But first, we rename the `id` column (which is simply an index of each utterance) using the `rename` function from the `dplyr` package. Then, we clean the file name column (called `files`) so that it only contains the name of the file, so we remove the rest of the path information that we do not need anymore. We do this by using the `mutate` function from the `dplyr` package  (which changes columns or creates new columns). Within the `mutate` function, we use the `gsub` function which substitutes something with something else: here the full path is replaced with on that part of the path that contains the file name. The `gsub` function has the following form

> gsub(*look for pattern*, *replacement of the pattern*, object)

This means that the `gsub` function needs an object and in that object it looks for a pattern and then replaces instances f that pattern with something.

In our case, that what we look for is the file name which is located between the symbol `/` and the file ending (`.cha`). So, we extract everything that comes between a `/` and a `.cha` in the path and keep that what is between the `/` and a `.cha`  in R's memory (this is done by placing something in round brackets in a regular expression). Then, we paste that what we have extracted back (and which is stored in memory) by using the `\\1` which grabs the first element that is in memory and puts it into the *replace with* part of the `gsub` function. 



```{r childes_01_10, message=F, warning=F}
childes <- chitb %>%
  # rename id column
  dplyr::rename(id = colnames(chitb)[1]) %>%
  # clean file names
  dplyr::mutate(files = gsub(".*/(.*?).cha", "\\1", files))
```


Let's have a look at the data.

```{r childes_01_12, echo = F, message=F, warning=F}
# inspect data
flextable::flextable(head(childes, 3)) %>%
  flextable::autofit()
```

We now continue in the same manner (by remove what is before what interests us and what comes after) and thereby extract pieces of information that we store in new columns.

Creating a speaker column. We create a new column called `speaker` using the `mutate` function from the `dplyr` package. Then, we use the `str_replace_all` function from the `stringr` package to remove everything that comes after a `:`. *Everything that comes after* can be defined by a regular expression - in this case the sequence `.*`. The `.` is a regular expression that stands for *any symbol* - be it a letter, or a number, or any punctuation symbol, or a white space. The `*` is a numerating regular expression that tells R how many times the regular expression (the `.`) is repeated - in our case, the `*` stands for *zero to an infinite number*. So the sequence `.*` stands for any symbol, repeated zero to an infinite number of times. In combination, the sequence `:.*` stands for *look for a colon and anything that comes after. And because we have put this into the `str_replace_all` function, the colon adn everything that comes after is removed.

```{r childes_01_14, message=F, warning=F}
childes <- childes %>%  
  dplyr::mutate(speaker = stringr::str_remove_all(rawcontent, ":.*"),
                speaker = stringr::str_remove_all(speaker, "\\W"))
```  

In the following, we will create many different columns, but we will always follow the same scheme: generate a new column using the `mutate` function from the `dplyr` package and then remove stuff that we do not need by using the `str_remove_all` function from the `stringr` package or just the `gsub` function - which is a simple replacement function. We can also use `str_squish` to get rid of superfluous white spaces. We will always remove sequences that are defined by a string (a sequence of characters and a regular expression consisting of the regular expression that determines what type of symbol R is supposed to look for and a numerator which tells R how many times that symbol can occur). For example, `%mor:.*` tells R to look for the sequence `%mor:` and any symbol, repeated between zero and an infinite number of times, that comes after the `%mor:` sequence. As thsi is put into the `str_replace_all` function and applied to the `rawcontent` file, it will replace everything that comes after `%mor:` and the sequence `%mor:` itself.

Creating an utterance column.

```{r childes_01_15, message=F, warning=F}
childes <- childes %>%  
  dplyr::mutate(utterance = stringr::str_remove_all(rawcontent, "%mor:.*"),
                utterance = stringr::str_remove_all(utterance, "%gpx:.*"),
                utterance = stringr::str_remove_all(utterance, "%act:.*"),
                utterance = stringr::str_remove_all(utterance, "%par:.*"),
                utterance = stringr::str_remove_all(utterance, "%add:.*"),
                utterance = stringr::str_remove_all(utterance, "\\*\\w{2,6}:"),
                utterance = stringr::str_squish(utterance))
```  

Creating a column with the pos-tagged utterances.

```{r childes_01_16, message=F, warning=F}
childes <- childes %>%  
  dplyr::mutate(postag = stringr::str_remove_all(rawcontent, ".*%mor:"),
                postag = stringr::str_remove_all(postag, "%.*"),
                postag = stringr::str_remove_all(postag, "\\*\\w{2,6}:"),
                postag = stringr::str_squish(postag))
```  

Creating a  column with comments. In the following chunk, we use the `?` in combination with `.*`. In this case, the `?` does not mean the literal symbol `?` but it tells R to be what is called *non-greedy* which means that R will look for something until the first occurrence of something. So the sequence `.*?%` tells R to look for any symbol repeated between zero and an infinite number of times until *the first occurrence*(!) of the symbol `%`. If we did not include the `?`, R would look until the last (not the first) occurrence of `%`.

```{r childes_01_17, message=F, warning=F}
childes <- childes %>%  
  dplyr::mutate(comment = stringr::str_remove_all(rawcontent, ".*%mor:"),
                comment = stringr::str_remove(comment, ".*?%"),
                comment = stringr::str_remove_all(comment, ".*|.*"),
                comment = stringr::str_squish(comment))
```  

Creating a  column with the participants that were present during the recording.

```{r childes_01_18, message=F, warning=F}
childes <- childes %>%  
  dplyr::mutate(participants = gsub(".*@Participants:(.*?)@.*", "\\1", fileinfo))
```  

Creating a  column with the age of the target child. In the following, the sequence `[0-9]{1,3}` means look for any sequence containing between 1 and 3 (this is defined by the `{1,3}`) numbers (the numbers are defined by the `[0-9]` part). Also, when we put `\\` before something, then we tell R that this refers to the actual symbol and not its meaning as a regular expression. For example, the symbol `|` is a regular expression that means *or* as in *You can paint my walls blue OR orange*, but if we put `\\` before `|`, we tell R that we really mean the symbol `|`.

```{r childes_01_19, message=F, warning=F}
childes <- childes %>%
  dplyr::mutate(age_targetchild = gsub(".*\\|([0-9]{1,3};[0-9]{1,3}\\.[0-9]{1,3})\\|.*", "\\1", fileinfo)) 
```  

Creating a  column with the age of the target child in years.

```{r childes_01_20, message=F, warning=F}
childes <- childes %>%
  dplyr::mutate(age_years_targetchild = stringr::str_remove_all(age_targetchild, ";.*")) 
```  

Creating a  column with the gender of the target child.

```{r childes_01_21, message=F, warning=F}
childes <- childes %>%
  dplyr::mutate(gender_targetchild = gsub(".*\\|([female]{4,6})\\|.*", "\\1", fileinfo))
```

Creating columns with the date-of-birth of the target child, more comments, and the date of the recording.


```{r childes_01_22, message=F, warning=F}
childes <- childes %>%  
  # create dob_targetchild column
  dplyr::mutate(dob_targetchild = gsub(".*@Birth of CHI:(.*?)@.*","\\1", fileinfo)) %>%
  # create comment_file column
  dplyr::mutate(comment_file = gsub(".*@Comment: (.*?)@.*", "\\1", fileinfo)) %>%
  # create date column
  dplyr::mutate(date = gsub(".*@Date: (.*?)@.*", "\\1", fileinfo))
```  

Creating columns with the location where the recording took place and the situation type of the recording.

```{r childes_01_23, message=F, warning=F}
childes <- childes %>%  
  # create location column,
  dplyr::mutate(location = gsub(".*@Location: (.*?)@.*", "\\1", fileinfo)) %>%
  # create situation column
  dplyr::mutate(situation = gsub(".*@Situation: (.*?)@.*", "\\1", fileinfo))
```  

Creating columns with the activity during the recording and the homevisit number.

```{r childes_01_24, message=F, warning=F}
childes <- childes %>%  
  # create homevisit_activity column
  dplyr::mutate(homevisit_activity = stringr::str_remove_all(situation, ";.*")) %>%
  # create activity column
  dplyr::mutate(activity = gsub(".*@Activities: (.*?)@.*", "\\1", fileinfo)) %>%
  # create homevisit column
  dplyr::mutate(homevisit = stringr::str_sub(files, 4, 6))
```  

Creating a column with the number of words in each utterance.

```{r childes_01_25, message=F, warning=F}
childes <- childes %>%  
  # create words column
  dplyr::mutate(words = stringr::str_replace_all(utterance, "\\W", " "),
                words = stringr::str_squish(words),
                words = stringr::str_count(words, "\\w+"))
```  

Cleaning the data: removing rows without speakers, rows where the age of the target child was incotrrect, and removing superfluous columns.

```{r childes_01_26, message=F, warning=F}
childes <- childes %>%  
  # remove rows without speakers (contain only metadata)
  dplyr::filter(speaker != "") %>%
  # remove rows with incorrect age of child
  dplyr::filter(nchar(age_years_targetchild) < 5) %>%
  # remove superfluous columns
  dplyr::select(-fileinfo, -rawcontent, -situation)
```

```{r childes_01_27, echo = F, message=F, warning=F}
# inspect data
flextable::flextable(head(childes)) %>%
  flextable::autofit()
```

Check the speakers.

```{r childes_01_28, message=F, warning=F}
table(childes$speaker)
```

We can use the table of speakers to classify speakers into different groups (e.g. siblings (SIB), secondary (SCG) and primary caregivers (PCG), and everyone else. In addition, we add proper labels to the activities.

```{r childes_01_29, message=F, warning=F}
# define groups for siblings and peers.
SIB <- c("BR1", "BR2", "BR3", "BRI", "BRO", "BRO1", "BRO2", "SI1",
         "SI2", "SI3", "SIS", "SIS1", "SIS2", "SIS3", "CO2", "CO3", 
         "COS", "COU", "COU2", "COU3", "FRE", "FRI", "KID", "FR1", 
         "FRE", "FRI")
# define group for primary caregivers
PCG <- c("MOT", "FAT")
# define group for secondary caregivers
SCG <- c("ANT", "AUN", "GFA", "GMA", "GPA", "GRA", "GRM", "UNC")
# clean column names and add interlocutor column
childes <- childes %>%
  # create interlocutor
  dplyr::mutate(interlocutor = dplyr::case_when(speaker %in% SIB ~ "peer",
                                                speaker %in% PCG ~ "primarycaregiver",
                                                speaker %in% SCG ~ "secondarycaregiver",
                                                speaker == "CHI" ~ "child", 
                                                T ~ "other")) %>%
  # code activity
  dplyr::mutate(visit = substr(files, 6, 6)) %>%
  dplyr::mutate(situation = substr(files, 4, 5),
                situation =  str_replace_all(situation, "br", "Book reading"),
                situation = str_replace_all(situation, "er", "Elicited report"),
                situation = str_replace_all(situation, "et", "Experimental task"),
                situation = str_replace_all(situation, "lw", "Letter writing"),
                situation = str_replace_all(situation, "md", "Mother defined situation"),
                situation = str_replace_all(situation, "mt", "Meal time"),
                situation = str_replace_all(situation, "re", "Reading"),
                situation = str_replace_all(situation, "tp", "Toy play"))
# inspect data
table(childes$interlocutor)
```

# Saving the CHILDES table on your computer 

Now that we have the data in a neat format, we may want to store the data on our computer. To save this table on your computer, you can use the `write.table` function and the `here` function as shown below. The first argument that the `write.table` needs is the object that we want to save. Then it needs to now a path, i.e., where to store the data. Regarding this path, it makes sense to use the `here` function because the `here` function creates nice paths. The `sep` and `row.names` arguments tells R how to store the data.

```{r}
childes <- childes %>%  
  # create words column
  dplyr::mutate(collection = "EngNA",
                corpus = "HSLLD") %>%
  dplyr::rename(transcript_id = files)
```

```{r childes_01_39, message=F, warning=F}
base::saveRDS(childes, file = here::here("data", "childes.rda"))
write.table(childes, here::here("data", "EngNA_HSLLD.txt"), sep = "\t", row.names = F)
```

# Case studies

Now that we have the data in a format that we can use, we can use this table to perform searches.

In case the above processing has not worked for you, simply visit `https://github.com/AcqVALab/RCHILDES/` and download the file manually. If you store that file in your `data` folder, you can load it by executing the code chunk below.

```{r childes_01_40b, message=F, warning=F}
childes <- base::readRDS(here::here("data", "childes.rda"))
# inspect data
childes[1:3, 1:4]
```


## Example 1: Extract uses of the word "No" by children {-}

To extract all instances of a single word, in this example the word *no*, that are uttered by a specific interlocutor we filter by speaker and define that we only want rows where the speaker is equal to `CHI` (target child).


```{r childes_01_41, message=F, warning=F}
no <- childes %>%
  dplyr::filter(speaker == "CHI") %>%
  dplyr::filter(stringr::str_detect(utterance, "\\b[Yy][Ee][Ss]\\b")) # yES
```


```{r childes_01_42, echo = F, message=F, warning=F}
# inspect data
flextable::flextable(head(no)) %>%
  flextable::autofit()
```

We summarize the results in a table. 

```{r childes_01_43, message=F, warning=F}
no_no <- no %>%
  dplyr::group_by(files, gender_targetchild, age_years_targetchild) %>%
  dplyr::summarise(nos = nrow(.))
head(no_no)
```


We can also extract the number of words uttered by children to check if the use of *no* shows a relative increase or decrease over time.

```{r childes_01_44, message=F, warning=F}
no_words <- childes %>%
  dplyr::filter(speaker == "CHI") %>%
  dplyr::group_by(files, gender_targetchild, age_years_targetchild) %>%
  dplyr::mutate(nos = stringr::str_detect(utterance, "\\b[Nn][Oo]\\b")) %>%
  dplyr::summarise(nos = sum(nos),
                   words = sum(words)) %>%
  # add relative frequency
  dplyr::mutate(freq = round(nos/words*1000, 3))
# inspect data
head(no_words)
```

We can also visualize the trends using the `ggplot` function . To learn how to visualize data in R see [this tutorial](https://slcladal.github.io/dviz.html).

```{r childes_01_45, message=F, warning=F}
no_words %>%
  dplyr::mutate(age_years_targetchild = as.numeric(age_years_targetchild)) %>%
  ggplot(aes(x = age_years_targetchild, y = freq)) +
  geom_smooth() +
  theme_bw() +
  labs(x = "Age of target child", y = "Relative frequency of NOs \n (per 1,000 words)")
```


## Example 2: Extracting all questions by mothers {-}

Here, we want to extract all questions uttered by mothers. We operationalize questions as utterances containing a question mark.

```{r childes_01_50, message=F, warning=F}
questions <- childes %>%
  dplyr::filter(speaker == "MOT") %>%
  dplyr::filter(stringr::str_detect(utterance, "\\?"))
# inspect data
head(questions)
```

We could now check if the rate of questions changes over time.


```{r childes_01_51, message=F, warning=F}
qmot <- childes %>%
  dplyr::filter(speaker == "MOT") %>%
  dplyr::mutate(questions = ifelse(stringr::str_detect(utterance, "\\?") == T, 1,0),
                utterances = 1) %>%
  dplyr::group_by(age_years_targetchild) %>%
  dplyr::summarise(utterances = sum(utterances),
                questions = sum(questions),
                percent = round(questions/utterances*100, 2))
# inspect data
head(qmot)
```

```{r childes_01_52, message=F, warning=F}
qmot %>%
  dplyr::mutate(age_years_targetchild = as.numeric(age_years_targetchild)) %>%
  ggplot(aes(x = age_years_targetchild, y = percent)) +
  geom_smooth() +
  theme_bw() +
  labs(x = "Age of target child", y = "Percent \n (questions)")
```

## Example 3: Extracting aux + part by mothers {-}

Here we want to extract all occurrences of an auxiliary plus a participle (e.g. *is swimming*) produced by mothers.

```{r childes_01_55, message=F, warning=F}
auxv <- childes %>%
  dplyr::filter(speaker == "MOT") %>%
  dplyr::filter(stringr::str_detect(postag, "aux\\|\\S{1,} part\\|"))
# inspect data
head(auxv)
```

We can now extract all the particle forms from the pos-tagged utterance


```{r childes_01_56, message=F, warning=F}
auxv_verbs <- auxv %>%
  dplyr::mutate(participle = gsub(".*part\\|(\\w{1,})-.*", "\\1", postag)) %>%
  dplyr::pull(participle)
head(auxv_verbs)
```

```{r childes_01_57, message=F, warning=F}
auxv_verbs_df <- auxv_verbs %>%
  as.data.frame(.)  %>%
  dplyr::rename("verb" = colnames(.)[1]) %>%
  dplyr::group_by(verb) %>%
  dplyr::summarise(freq = n()) %>%
  dplyr::arrange(-freq) %>%
  head(20)
# inspect
head(auxv_verbs_df)
```

We can again visualize the results. In this case, we create a bar plot (see the `geom_bar`).

```{r childes_01_58, message=F, warning=F}
auxv_verbs_df %>%
  ggplot(aes(x = reorder(verb, -freq), y = freq)) +
  geom_bar(stat = "identity") +
  theme_bw() +
  labs(x = "Verb", y = "Frequency") +
  theme(axis.text.x = element_text(angle = 90))
```


## Example 4: How many verbs do children use by age? {-}

Here we extract all lexical verbs and words uttered by children by year and then see if the rate of verbs changes over time.

```{r childes_01_60, message=F, warning=F}
nverbs <- childes %>%
  dplyr::filter(speaker == "CHI") %>%
  dplyr::mutate(nverbs = stringr::str_count(postag, "^v\\|| v\\|"),
  age_years_targetchild = as.numeric(age_years_targetchild)) %>%
  dplyr::group_by(age_years_targetchild) %>%
  dplyr::summarise(words = sum(words),
                verbs = sum(nverbs)) %>%
  dplyr::mutate(verb.word.ratio = round(verbs/words, 3))
# inspect data
nverbs
```


We can also visualize the results to show any changes over time. 

```{r childes_01_61, message=F, warning=F}
nverbs %>%
  ggplot(aes(x = age_years_targetchild, y = verb.word.ratio)) +
  geom_line() +
  coord_cartesian(ylim = c(0, 0.2)) +
  theme_bw() +
  labs(x = "Age of target child", y = "Verb-Word Ratio")
```

## Example 5: Does the type-token ratio of the output of children change as they mature? {-}

Here we extract all tokens (words with repetition) and types (words without repetition) uttered by children by year and then see if the type-token ratio changes over time.

In a first step, we create a table with the age of the children in years, we then collapse all utterances of the children into one long utterance and then clean this long utterance by removing digits and superfluous white spaces.

> Tip: A more accurate way of doing this would be to create one utterance for each child per home visit as this would give us a dsitribution of type-token rtaiosn rather than a single value.

```{r childes_01_62, message=F, warning=F}
utterance_tb <- childes %>%
  dplyr::filter(speaker == "CHI") %>%
  dplyr::group_by(age_years_targetchild) %>%
  dplyr::summarise(allutts = paste0(utterance, collapse = " ")) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(age_years_targetchild = as.numeric(age_years_targetchild),
                # clean utterance
                allutts = stringr::str_replace_all(allutts, "\\W", " "),
                allutts = stringr::str_replace_all(allutts, "\\d", " "),
                allutts = stringr::str_remove_all(allutts, "xxx"),
                allutts = stringr::str_remove_all(allutts, "zzz"),
                allutts = tolower(allutts)) %>%
  # remove superfluous white spaces
  dplyr::mutate(allutts = gsub(" {2,}", " ", allutts)) %>%
  dplyr::mutate(allutts = stringr::str_squish(allutts))
# inspect data
head(utterance_tb)
```

Extract the number of tokens, the number of types and calculating the type-token ratio.

```{r childes_01_63, message=F, warning=F}
tokens <- stringr::str_count(utterance_tb$allutts, " ") +1
types <- stringr::str_split(utterance_tb$allutts, " ")
types <- sapply(types, function(x){
  x <- length(names(table(x)))
})
ttr <- utterance_tb %>%
  dplyr::mutate(tokens = tokens,
                types = types) %>%
  dplyr::select(-allutts) %>%
  dplyr::mutate(TypeTokenRatio = round(types/tokens, 3))
# inspect 
ttr
```

Plot the type-token ratio against age of the target child.

```{r childes_01_64, message=F, warning=F}
ttr %>%
  ggplot(aes(x = age_years_targetchild, y = TypeTokenRatio)) +
  geom_line() +
  coord_cartesian(ylim = c(0, 0.75)) +
  theme_bw() +
  labs(x = "Age of target child", y = "Type-Token Ratio")
```

# Saving data to your computer{-}

To save results on your computer, you can use the `write.table` function as shown below.

```{r childes_01_65, message=F, warning=F}
write.table(ttr, here::here("tables", "ttr.txt"), sep = "\t", row.names = F)
```


***

# Citation & Session Info {-}

Schweinberger, Martin. `r format(Sys.time(), '%Y')`. *Working with the Child Language Data Exchange System (CHILDES) using R*. TromsÃ¸: The Artic University of Norway. url: https://slcladal.github.io/mmws.html (Version `r format(Sys.time(), '%Y.%m.%d')`).

```
@manual{schweinberger`r format(Sys.time(), '%Y')`mmws,
  author = {Schweinberger, Martin},
  title = {Working with the Child Language Data Exchange System (CHILDES) using R},
  note = {https://slcladal.github.io/mmws.html},
  year = {2021},
  organization = "Arctic University of Norway, AcqVA Aurora Center},
  address = {TromsÃ¸},
  edition = {`r format(Sys.time(), '%Y.%m.%d')`}
}
```

```{r fin}
sessionInfo()
```


***

[Back to top](#introduction)

***




